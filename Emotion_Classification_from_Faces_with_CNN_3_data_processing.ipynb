{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Classification from Faces with CNN & PyTorch - Part 3 - Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this series we will continue builind a model that will guess the emotion of a person from a facial expression. We will add techniques such as batch normalization and hyperparameters tuning, and add layers to make more advance models compared to part one.\n",
    "\n",
    "The model will be trained only with the seven basic emtotions identified by Ekman: anger, disgust, contempt, happiness, sadness, fear, surprise.\n",
    "\n",
    "Moreover, the model will look only at photos of real people (no cartoon or generated images), to capture microexpressions, which are crucual to give high accuracy to such a model. In fact, humans heavily rely on microexpressions to distinguish between different emotions in the arc of milliseconds (e.g., fear from surprise, disgust from contempt), and taking those out of the equations would mean removing key elememnts. A challenge might be increasing the quality of the images used for training, then burdening the computational power with an heavier dataset. Feature engineering might be key in selecting the parts of the images that are the most relevant, eliminating everything else.\n",
    "\n",
    "Finally we will build different Convolutional Neural Networks and evaluate the different models. Since the whole process will take a significant amount of code, the work will be divided into different notebooks linking to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first notebook focused in loading, cleaning, and augmenting the data. Whereas the first part of the modelling testes different combinations of models and make observations.\n",
    "- [Emotion Recognition from Faces with CNN - Exploratory Data Analysis (EDA)](https://www.kaggle.com/code/gabrielenoaro/emotion-recognition-from-faces-with-cnn-eda)\n",
    "- [Emotion_Classification_from_Faces_with_CNN_Part_1](https://www.kaggle.com/code/gabrielenoaro/emotion-recognition-from-faces-with-cnn-pytorch-1)\n",
    "- [Emotion_Classification_from_Faces_with_CNN_Part_2](https://www.kaggle.com/code/gabrielenoaro/emotion-classification-from-faces-with-cnn-part-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the part relative to data preprocessing here:\n",
    "- [Emotion Classification from Faces CNN 3 Models](https://www.kaggle.com/code/gabrielenoaro/emotion-classification-from-faces-cnn-3-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have already loaded, cleaned, and inspected the data in our previous notebook [Emotion Recognition from Faces with CNN - Exploratory Data Analysis (EDA)](https://www.kaggle.com/code/gabrielenoaro/emotion-recognition-from-faces-with-cnn-eda), we will jump directly to data preprocessing.\n",
    "\n",
    "In this notebook we want to to eliminate heavily underrepresented classes, perform random data reduction on overepresented classes, and do some data augmentation on the training set.\n",
    "\n",
    "This will help us solve the data leakage and overfitting issues we encountered in  ([Emotion_Classification_from_Faces_with_CNN_Part_2](https://www.kaggle.com/code/gabrielenoaro/emotion-classification-from-faces-with-cnn-part-2))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Load the libraries](#load-the-data)\n",
    "2. [Helper functions for data processing](#helper-functions-for-data-proccessing)\n",
    "3. [Exploratory Data Analysis](#exploratory-data-analysis)\n",
    "4. [Data preprocessing, splitting, and augmentation](#data-preprocessing-splitting-and-augmentation)\n",
    "\n",
    "3. [Split the data](#split-the-data)\n",
    "4. [Build the models](#build-the-models)    \n",
    "5. [Train and test the models](#train-and-test-the-models)\n",
    "\n",
    "    5.1 [Define the hyperparameters](#define-the-hyperparameters)\n",
    "\n",
    "    5.2 [Helper functions for training, testing, and plotting](#helper-functions-for-training-testing-and-plotting)\n",
    "    \n",
    "    5.3 [Train the models](#train-the-models)\n",
    "    \n",
    "    5.4 [Test the models](#test-the-models)\n",
    "\n",
    "    5.5 [Table with the results of the different models](#table-with-the-results-of-the-different-models)\n",
    "\n",
    "    5.6 [Confusion matrix of the best model](#confusion-matrix-of-the-best-model)\n",
    "\n",
    "6. [Conclusions](#conclusions)\n",
    "\n",
    "    6.1 [Observations](#observations)\n",
    "\n",
    "    6.2 [Lessons learned](#lessons-learned)\n",
    "\n",
    "    6.3 [Limitations with the data](#limitations-with-the-data)\n",
    "\n",
    "    6.4 [Next steps](#next-steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "from hashlib import md5\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, ParameterSampler\n",
    "\n",
    "import os,cv2\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want also to set a random seed to maintain consistency across our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cover all the potential cases with the random seed\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True  # Ensure deterministic behavior.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for data prerocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image_info(images, labels, stage):\n",
    "    unique_labels = set(labels)\n",
    "    print(f\"Stage: {stage}\")\n",
    "    print(f\"Number of images: {len(images)}\")\n",
    "    print(f\"Number of labels: {len(labels)}\")\n",
    "    print(f\"Image shape: {images[0].shape}\")\n",
    "    print(f\"Image dtype: {images[0].dtype}\")\n",
    "    print(f\"Unique labels: {unique_labels}\")\n",
    "    for label in unique_labels:\n",
    "        label_images = [img for img, lbl in zip(images, labels) if lbl == label]\n",
    "        if label_images:\n",
    "            print(f\"Class: {label}, Image shape: {label_images[0].shape}, dtype: {label_images[0].dtype}, min: {label_images[0].min()}, max: {label_images[0].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform random data reduction on overrepresented classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_majority_classes(input_pickle_file, output_pickle_file, max_samples_per_class):\n",
    "    with open(input_pickle_file, 'rb') as f:\n",
    "        img_data, img_labels = pickle.load(f)\n",
    "\n",
    "    print_image_info(img_data, img_labels, \"After loading in reduce_majority_classes\")\n",
    "\n",
    "    reduced_data = []\n",
    "    reduced_labels = []\n",
    "    label_counts = Counter(img_labels)\n",
    "\n",
    "    for label in np.unique(img_labels):\n",
    "        label_indices = np.where(img_labels == label)[0]\n",
    "        if label_counts[label] > max_samples_per_class:\n",
    "            label_indices = np.random.choice(label_indices, max_samples_per_class, replace=False)\n",
    "\n",
    "        reduced_data.extend(img_data[label_indices])\n",
    "        reduced_labels.extend(img_labels[label_indices])\n",
    "\n",
    "    reduced_data = np.array(reduced_data)\n",
    "    reduced_labels = np.array(reduced_labels)\n",
    "\n",
    "    print_image_info(reduced_data, reduced_labels, \"Before saving in reduce_majority_classes\")\n",
    "\n",
    "    with open(output_pickle_file, 'wb') as f:\n",
    "        pickle.dump((reduced_data, reduced_labels), f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess and transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess data\n",
    "def load_and_preprocess_images(input_pickle_file, output_pickle_file):\n",
    "    with open(input_pickle_file, 'rb') as f:\n",
    "        img_data, img_labels = pickle.load(f)\n",
    "    \n",
    "    # Convert images to float32\n",
    "    processed_images = [img.astype('float32') for img in img_data]\n",
    "    processed_images = np.array(processed_images)\n",
    "    \n",
    "    print_image_info(processed_images, img_labels, \"Preprocessed\")\n",
    "\n",
    "    with open(output_pickle_file, 'wb') as f:\n",
    "        pickle.dump((processed_images, img_labels), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(input_pickle_file, output_pickle_file, label_mapping_file):\n",
    "    # Load the data from the pickle file\n",
    "    with open(input_pickle_file, 'rb') as f:\n",
    "        img_data, img_labels = pickle.load(f)\n",
    "\n",
    "    # Print initial info\n",
    "    print_image_info(img_data, img_labels, \"After loading in encode_labels\")\n",
    "\n",
    "    # Check unique labels\n",
    "    unique_labels = set(img_labels)\n",
    "    print(f\"Unique labels before encoding: {unique_labels}\")\n",
    "\n",
    "    # Encode labels\n",
    "    sorted_labels = sorted(unique_labels)\n",
    "    label_to_int = {label: idx for idx, label in enumerate(sorted_labels)}\n",
    "    img_labels_int = np.array([label_to_int[label] for label in img_labels])\n",
    "\n",
    "    # Check encoded labels\n",
    "    unique_encoded_labels = set(img_labels_int)\n",
    "    print(f\"Unique labels after encoding: {unique_encoded_labels}\")\n",
    "\n",
    "    # Save encoded data\n",
    "    with open(output_pickle_file, 'wb') as f:\n",
    "        pickle.dump((img_data, img_labels_int), f)\n",
    "\n",
    "    # Save label mappings\n",
    "    label_mapping = {'label_to_int': label_to_int, 'int_to_label': {v: k for k, v in label_to_int.items()}}\n",
    "    with open(label_mapping_file, 'wb') as f:\n",
    "        pickle.dump(label_mapping, f)\n",
    "\n",
    "    # Print final info\n",
    "    print_image_info(img_data, img_labels_int, \"After encoding labels\")\n",
    "    print(\"Label mapping saved:\")\n",
    "    print(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def split_data(input_pickle_file, train_output_file, val_output_file, test_output_file):\n",
    "    with open(input_pickle_file, 'rb') as f:\n",
    "        img_data, img_labels = pickle.load(f)\n",
    "\n",
    "    print_image_info(img_data, img_labels, \"After loading in split_data\")\n",
    "\n",
    "    train_data, temp_data, train_labels, temp_labels = train_test_split(img_data, img_labels, test_size=0.3, stratify=img_labels, random_state=42)\n",
    "    val_data, test_data, val_labels, test_labels = train_test_split(temp_data, temp_labels, test_size=0.4, stratify=temp_labels, random_state=42)\n",
    "\n",
    "    print_image_info(train_data, train_labels, \"Train data in split_data\")\n",
    "    print_image_info(val_data, val_labels, \"Validation data in split_data\")\n",
    "    print_image_info(test_data, test_labels, \"Test data in split_data\")\n",
    "\n",
    "    with open(train_output_file, 'wb') as f:\n",
    "        pickle.dump((train_data, train_labels), f)\n",
    "\n",
    "    with open(val_output_file, 'wb') as f:\n",
    "        pickle.dump((val_data, val_labels), f)\n",
    "\n",
    "    with open(test_output_file, 'wb') as f:\n",
    "        pickle.dump((test_data, test_labels), f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_images(images, labels, label_mapping, title):\n",
    "    fig, axs = plt.subplots(1, len(label_mapping), figsize=(15, 7))\n",
    "    class_to_images = {}\n",
    "    for img, label in zip(images, labels):\n",
    "        if label not in class_to_images:\n",
    "            class_to_images[label] = []\n",
    "        class_to_images[label].append(img)\n",
    "\n",
    "    for i, (label, images) in enumerate(class_to_images.items()):\n",
    "        img = random.choice(images)\n",
    "        img = img.squeeze()\n",
    "        ax = axs[i]\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(f\"Class: {label_mapping[label]}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert sets into PIL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pil(training_set_pickle, val_set_pickle, test_set_pickle):\n",
    "    def convert(img):\n",
    "        img_pil = Image.fromarray((img * 255).astype(np.uint8), mode='L')\n",
    "        return img_pil\n",
    "\n",
    "    def process_and_save(input_pickle_file, output_pickle_file, set_name):\n",
    "        # Load the dataset\n",
    "        with open(input_pickle_file, 'rb') as f:\n",
    "            img_data, img_labels = pickle.load(f)\n",
    "\n",
    "        # Debug info before conversion\n",
    "        print(f\"Stage: {set_name} Before Conversion to PIL\")\n",
    "        print(f\"Number of images: {len(img_data)}\")\n",
    "        print(f\"Image shape: {img_data[0].shape}\")\n",
    "        print(f\"Image dtype: {img_data[0].dtype}\")\n",
    "        print(\"----\")\n",
    "\n",
    "        # Visualize sample images before conversion\n",
    "        with open('label_mapping.pkl', 'rb') as f:\n",
    "            label_mapping = pickle.load(f)\n",
    "        int_to_label = label_mapping['int_to_label']\n",
    "\n",
    "        visualize_sample_images(img_data, img_labels, int_to_label, f\"Before Conversion - {set_name}\")\n",
    "\n",
    "        # Convert each image to PIL format\n",
    "        img_data_pil = [convert(img) for img in img_data]\n",
    "\n",
    "        # Save the converted dataset to a pickle file\n",
    "        with open(output_pickle_file, 'wb') as f:\n",
    "            pickle.dump((img_data_pil, img_labels), f)\n",
    "\n",
    "        # Debug info after conversion\n",
    "        print(f\"Stage: {set_name} Converted to PIL\")\n",
    "        print(f\"Number of images: {len(img_data_pil)}\")\n",
    "        print(f\"Image size: {img_data_pil[0].size}\")\n",
    "        print(f\"Image mode: {img_data_pil[0].mode}\")\n",
    "        print(\"----\")\n",
    "\n",
    "    # Convert and save each dataset separately\n",
    "    process_and_save(training_set_pickle, 'pil_train_data.pkl', 'Training')\n",
    "    process_and_save(val_set_pickle, 'pil_val_data.pkl', 'Validation')\n",
    "    process_and_save(test_set_pickle, 'pil_test_data.pkl', 'Test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment the data in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image_info(images, labels, stage):\n",
    "    print(f\"Stage: {stage}\")\n",
    "    print(f\"Number of images: {len(images)}\")\n",
    "    print(f\"Number of labels: {len(labels)}\")\n",
    "\n",
    "    if isinstance(images[0], np.ndarray):\n",
    "        print(f\"Image shape: {images[0].shape}\")\n",
    "        print(f\"Image dtype: {images[0].dtype}\")\n",
    "    elif isinstance(images[0], Image.Image):\n",
    "        print(f\"Image size: {images[0].size}\")\n",
    "        print(f\"Image mode: {images[0].mode}\")\n",
    "\n",
    "    unique_labels = set(labels)\n",
    "    print(f\"Unique labels: {unique_labels}\")\n",
    "    print(\"----\")\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(60),\n",
    "    transforms.RandomResizedCrop(48, scale=(0.8, 1.0))\n",
    "])\n",
    "\n",
    "def augment_images(img_data_pil, target_count):\n",
    "    augmented_images_pil = []\n",
    "\n",
    "    while len(augmented_images_pil) + len(img_data_pil) < target_count:\n",
    "        for img_pil in img_data_pil:\n",
    "            if len(augmented_images_pil) + len(img_data_pil) >= target_count:\n",
    "                break\n",
    "\n",
    "            # Apply data transformations\n",
    "            augmented_img_pil = data_transforms(img_pil)\n",
    "            augmented_images_pil.append(augmented_img_pil)\n",
    "    \n",
    "    print_image_info(augmented_images_pil, [None]*len(augmented_images_pil), \"Augmented\")\n",
    "    return augmented_images_pil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(input_pickle_file, output_pickle_file, target_number_of_images):\n",
    "    # Load the data from the pickle file\n",
    "    with open(input_pickle_file, 'rb') as f:\n",
    "        img_data, img_labels = pickle.load(f)\n",
    "\n",
    "    # Load the label mappings\n",
    "    with open('label_mapping.pkl', 'rb') as f:\n",
    "        label_mapping = pickle.load(f)\n",
    "    int_to_label = label_mapping['int_to_label']\n",
    "\n",
    "    # Combine images and labels into a dictionary\n",
    "    img_data_dict = {label: [] for label in set(img_labels)}\n",
    "    for img, label in zip(img_data, img_labels):\n",
    "        img_data_dict[label].append(img)\n",
    "\n",
    "    # Balance the dataset\n",
    "    balanced_img_data_dict = {}\n",
    "\n",
    "    for label, img_list in img_data_dict.items():\n",
    "        print(f'Processing {label}, {len(img_list)} images')\n",
    "\n",
    "        if len(img_list) < target_number_of_images:\n",
    "            augmented_imgs = augment_images(img_list, target_number_of_images)\n",
    "            balanced_img_data_dict[label] = img_list + augmented_imgs\n",
    "        else:\n",
    "            balanced_img_data_dict[label] = img_list\n",
    "\n",
    "        with open(f'{label}_balanced_images.pkl', 'wb') as f:\n",
    "            pickle.dump(balanced_img_data_dict[label], f)\n",
    "        print(f'{label}_balanced_images.pkl has been saved with {len(balanced_img_data_dict[label])} images')\n",
    "\n",
    "    balanced_img_data = []\n",
    "    balanced_img_labels = []\n",
    "    for label, imgs in balanced_img_data_dict.items():\n",
    "        balanced_img_data.extend(imgs)\n",
    "        balanced_img_labels.extend([label] * len(imgs))\n",
    "\n",
    "    balanced_img_data = np.array(balanced_img_data)\n",
    "    balanced_img_labels = np.array(balanced_img_labels)\n",
    "\n",
    "    with open(output_pickle_file, 'wb') as f:\n",
    "        pickle.dump((balanced_img_data, balanced_img_labels), f)\n",
    "    print(f'{output_pickle_file} has been saved')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert sets back to Numpy arrays and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numpy_array(pil_augmented_train_data, pil_val_data, pil_test_data):\n",
    "    def convert_back(img_pil):\n",
    "        img_numpy = np.array(img_pil).astype('float32') / 255.0\n",
    "        if img_numpy.ndim == 2:\n",
    "            img_numpy = np.expand_dims(img_numpy, axis=0)\n",
    "        elif img_numpy.ndim == 3 and img_numpy.shape[2] == 1:\n",
    "            img_numpy = np.squeeze(img_numpy, axis=2)\n",
    "            img_numpy = np.expand_dims(img_numpy, axis=0)\n",
    "        return img_numpy\n",
    "\n",
    "    def process_and_save(input_pickle_file, output_pickle_file, set_name):\n",
    "        # Load the dataset\n",
    "        with open(input_pickle_file, 'rb') as f:\n",
    "            img_data_pil, img_labels = pickle.load(f)\n",
    "\n",
    "        # Convert each image back to numpy array\n",
    "        img_data_numpy = [convert_back(img) for img in img_data_pil]\n",
    "\n",
    "        # Save the converted dataset to a pickle file\n",
    "        with open(output_pickle_file, 'wb') as f:\n",
    "            pickle.dump((img_data_numpy, img_labels), f)\n",
    "\n",
    "        # Debug info\n",
    "        print(f\"Stage: {set_name} Converted back to a numpy array\")\n",
    "        print(f\"Number of images: {len(img_data_numpy)}\")\n",
    "        print(f\"Image shape: {img_data_numpy[0].shape}\")\n",
    "        print(f\"Image dtype: {img_data_numpy[0].dtype}\")\n",
    "        print(\"----\")\n",
    "\n",
    "        # Visualize sample images\n",
    "        with open('label_mapping.pkl', 'rb') as f:\n",
    "            label_mapping = pickle.load(f)\n",
    "        int_to_label = label_mapping['int_to_label']\n",
    "\n",
    "        visualize_sample_images(img_data_numpy, img_labels, int_to_label, f\"After Conversion - {set_name}\")\n",
    "\n",
    "    # Convert and save each dataset separately\n",
    "    process_and_save(pil_augmented_train_data, 'numpy_train_data.pkl', 'Training')\n",
    "    process_and_save(pil_val_data, 'numpy_val_data.pkl', 'Validation')\n",
    "    process_and_save(pil_test_data, 'numpy_test_data.pkl', 'Test')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count and Plot the number of itmes for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to count and plot the items for each label\n",
    "def count_items_in_classes(dataset_file):\n",
    "    # Load the pickled data\n",
    "    with open(dataset_file, 'rb') as f:\n",
    "        img_data, img_labels = pickle.load(f)\n",
    "\n",
    "    # Count the occurrences of each label\n",
    "    unique_labels, counts = np.unique(img_labels, return_counts=True)\n",
    "    \n",
    "    # Print the counts for each label\n",
    "    for label, count in zip(unique_labels, counts):\n",
    "        print(f'Label {label}: {count} items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to cont and plot the items for each label\n",
    "def plot_items_in_classes(dataset_file):\n",
    "    # Load the pickled data\n",
    "    with open(dataset_file, 'rb') as f:\n",
    "        img_data, img_labels = pickle.load(f)\n",
    "\n",
    "    # Count the occurrences of each label\n",
    "    unique_labels, counts = np.unique(img_labels, return_counts=True)\n",
    "\n",
    "    # Create the bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(unique_labels, counts, color='skyblue')\n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title('Number of Images per Emotion Label')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the correctness of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load the pickled data and verify the images\n",
    "def verify_images(dataset_file):\n",
    "    with open(dataset_file, 'rb') as f:\n",
    "        img_data, img_labels = pickle.load(f)\n",
    "\n",
    "    # Randomly pick and plot one image from each class\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    unique_labels = np.unique(img_labels)\n",
    "    for idx, label in enumerate(unique_labels):\n",
    "        # Get all images for the current label\n",
    "        label_images = img_data[img_labels == label]\n",
    "\n",
    "        # Randomly select one image\n",
    "        random_image = random.choice(label_images)\n",
    "\n",
    "        plt.subplot(2, 4, idx + 1)\n",
    "        plt.imshow(random_image, cmap='gray')\n",
    "        plt.title(label)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_images(dataset_file):\n",
    "    with open(dataset_file, 'rb') as f:\n",
    "        img_data, img_labels = pickle.load(f)\n",
    "\n",
    "    # Load the label mappings\n",
    "    label_mapping_file = 'label_mapping.pkl'\n",
    "    with open(label_mapping_file, 'rb') as f:\n",
    "        label_mapping = pickle.load(f)\n",
    "    int_to_label = label_mapping['int_to_label']\n",
    "\n",
    "    # Organize images by class\n",
    "    class_to_images = {}\n",
    "    for img, label in zip(img_data, img_labels):\n",
    "        if label not in class_to_images:\n",
    "            class_to_images[label] = []\n",
    "        class_to_images[label].append(img)\n",
    "\n",
    "    # Plot one sample image for each class\n",
    "    num_classes = len(class_to_images)\n",
    "    fig, axs = plt.subplots(1, num_classes, figsize=(15, 5))\n",
    "\n",
    "    for i, (label, images) in enumerate(class_to_images.items()):\n",
    "        img = random.choice(images)\n",
    "        \n",
    "        # Ensure the image values are in [0, 1]\n",
    "        img = np.clip(img, 0.0, 1.0)\n",
    "        \n",
    "        # If the image has a singleton dimension, squeeze it\n",
    "        if img.shape[0] == 1:\n",
    "            img = img.squeeze(0)\n",
    "        else:\n",
    "            img = img.squeeze()\n",
    "        \n",
    "        # Debugging: Print image information\n",
    "        print(f\"Class: {int_to_label[label]}, Image shape: {img.shape}, dtype: {img.dtype}, min: {img.min()}, max: {img.max()}\")\n",
    "\n",
    "        # Display the image\n",
    "        ax = axs[i]\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(f\"Class: {int_to_label[label]}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove classes from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_classes_and_save(input_pickle_file, output_pickle_file, classes_to_remove):\n",
    "    # Load the pickled data\n",
    "    with open(input_pickle_file, 'rb') as f:\n",
    "        img_data, img_labels = pickle.load(f)\n",
    "    \n",
    "    # Create lists to store the filtered data\n",
    "    filtered_img_data = []\n",
    "    filtered_img_labels = []\n",
    "    \n",
    "    # Remove specified classes from the dataset\n",
    "    for img, label in zip(img_data, img_labels):\n",
    "        if label not in classes_to_remove:\n",
    "            filtered_img_data.append(img)\n",
    "            filtered_img_labels.append(label)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    filtered_img_data = np.array(filtered_img_data, dtype=np.float32)\n",
    "    filtered_img_labels = np.array(filtered_img_labels, dtype=img_labels.dtype)\n",
    "    \n",
    "    # Save the filtered dataset to a new pickle file\n",
    "    with open(output_pickle_file, 'wb') as f:\n",
    "        pickle.dump((filtered_img_data, filtered_img_labels), f)\n",
    "    \n",
    "    print(f\"Dataset without classes {classes_to_remove} saved to {output_pickle_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the data into PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensors(images, labels):\n",
    "    # Convert list of numpy arrays to a single numpy array\n",
    "    images_np = np.array(images)\n",
    "    labels_np = np.array(labels)\n",
    "    \n",
    "    # Convert images and labels to PyTorch tensors\n",
    "    all_images_tensor = torch.tensor(images_np, dtype=torch.float32)\n",
    "    all_labels_tensor = torch.tensor(labels_np, dtype=torch.int64)\n",
    "    \n",
    "    # Combine into a dataset\n",
    "    dataset = TensorDataset(all_images_tensor, all_labels_tensor)\n",
    "    return dataset\n",
    "\n",
    "def save_dataset_to_pickle(dataset, output_pickle_file):\n",
    "    with open(output_pickle_file, 'wb') as f:\n",
    "        pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Anger: 4977 items\n",
      "Label Contempt: 73 items\n",
      "Label Disgust: 743 items\n",
      "Label Fear: 5003 items\n",
      "Label Happiness: 9111 items\n",
      "Label Neutral: 6155 items\n",
      "Label Sadness: 6100 items\n",
      "Label Surprise: 3599 items\n"
     ]
    }
   ],
   "source": [
    "# Specify the input dataset file\n",
    "dataset_file = 'images_labels_no_duplicates.pkl'\n",
    "\n",
    "count_items_in_classes(dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disgust and especially Contempt are extremely underepresented classes, therefore we either need to dramatically reduce the size of all classes to fewer than 1000 or perhaps 500 images, find new images, or remove Contempt and Disgust from this particular experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove Disgust and Contempt because they are to underrepresented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset without classes ['Disgust', 'Contempt'] saved to images_labels_no_duplicates_no_dis_cont.pkl\n"
     ]
    }
   ],
   "source": [
    "input_pickle_file = 'images_labels_no_duplicates.pkl'\n",
    "output_pickle_file = 'images_labels_no_duplicates_no_dis_cont.pkl'\n",
    "classes_to_remove = ['Disgust', 'Contempt']\n",
    "\n",
    "remove_classes_and_save(input_pickle_file, output_pickle_file, classes_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Anger: 4977 items\n",
      "Label Fear: 5003 items\n",
      "Label Happiness: 9111 items\n",
      "Label Neutral: 6155 items\n",
      "Label Sadness: 6100 items\n",
      "Label Surprise: 3599 items\n"
     ]
    }
   ],
   "source": [
    "# Specify the input dataset file\n",
    "dataset_file = 'images_labels_no_duplicates_no_dis_cont.pkl'\n",
    "\n",
    "count_items_in_classes(dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Disgust and Contempt classes have been removed successfully, and the new dataset has been saved in a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify the input dataset file\n",
    "dataset_file = 'images_labels_no_duplicates_no_dis_cont.pkl'\n",
    "\n",
    "# Execute the verification function\n",
    "plot_items_in_classes(dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use the new function to randomly reduce the number of items in the Happiness class so it equals the Neutral class, then we can augment all classes to reach a cerain number of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing, splitting, and augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random data reduction to reduce class imbalances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if random data reduction on majority classes would make classes much more balanced, we tested the smaller dataset, and the model underfits the data. There is why we are going to train with a bigger dataset for the moment, even if classes are less balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pickle_file = \"images_labels_no_duplicates_no_dis_cont.pkl\"\n",
    "output_pickle_file = \"reduced_images_3.pkl\"\n",
    "#max_samples_per_class = 5003\n",
    "max_samples_per_class = 9111\n",
    "\n",
    "#Reduce majority classes\n",
    "reduce_majority_classes(input_pickle_file, output_pickle_file, max_samples_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process and transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pickle_file = \"reduced_images_3.pkl\"\n",
    "output_pickle_file = \"processed_images_3.pkl\"\n",
    "\n",
    "load_and_preprocess_images(input_pickle_file, output_pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_pickle_file = \"reduced_images_3.pkl\"\n",
    "input_pickle_file = 'processed_images_3.pkl'\n",
    "output_pickle_file = 'encoded_images.pkl'\n",
    "label_mapping = 'label_mapping.pkl'\n",
    "encode_labels(input_pickle_file, output_pickle_file, label_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we want to map the each label (string) into a corrresponding integer in a dictionary. Then we want to combine images and corresponding labels in separate lists and convert them into numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to sort the labels with a specific order (e.g., alphabetically), so each time we run the cell, we get the set of labels in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pickle_file = \"encoded_images.pkl\"\n",
    "train_output_file = 'train_data_3.pkl'\n",
    "val_output_file = 'val_data_3.pkl'\n",
    "test_output_file = 'test_data_3.pkl'\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#Split data into train, validation, and test sets\n",
    "split_data(input_pickle_file, train_output_file, val_output_file, test_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert sets into PIL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_pickle = 'train_data_3.pkl'\n",
    "val_set_pickle= 'val_data_3.pkl'\n",
    "test_set_pickle = 'test_data_3.pkl'\n",
    "\n",
    "convert_to_pil(training_set_pickle, val_set_pickle, test_set_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to apply a 60-degree random rotation, in contrast to the 10-degree random rotation we applied in the previous notebook. This is because humans generally, when bending their neck on the side, they do so by 40 to 80 degrees. Therefore, 60 degrees looks like a good compromise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pickle_file = 'pil_train_data.pkl'\n",
    "output_pickle_file = 'pil_train_data_augmented_3.pkl'\n",
    "#target_number_of_images = 8000\n",
    "target_number_of_images = 10000\n",
    "\n",
    "#Augment training data\n",
    "balance_dataset(input_pickle_file, output_pickle_file, target_number_of_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert back to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_augmented_train_data = 'pil_train_data_augmented_3.pkl'\n",
    "pil_val_data = 'pil_val_data.pkl'\n",
    "pil_test_data = 'pil_test_data.pkl'\n",
    "\n",
    "convert_to_numpy_array(pil_augmented_train_data, pil_val_data, pil_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the pickle file\n",
    "dataset_file = 'numpy_train_data.pkl'\n",
    "\n",
    "verify_images(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the pickle file\n",
    "dataset_file = 'numpy_val_data.pkl'\n",
    "\n",
    "verify_images(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the pickle file\n",
    "dataset_file = 'numpy_test_data.pkl'\n",
    "\n",
    "verify_images(dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the data has been uploaded correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and define the dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step we want to create dataloaders, which are utilities responsible of loading the data into the model in batches. We have also saved each dataset into a pickle file, so we can easily load them without having to run the code above each time we open this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from a pickle file\n",
    "#train_dataset = pd.read_pickle('train_data_augmented_3.pkl')\n",
    "train_dataset = pd.read_pickle('numpy_train_data.pkl')\n",
    "#train_dataset_original = pd.read_pickle('train_data_3.pkl')\n",
    "val_dataset = pd.read_pickle('numpy_val_data.pkl')\n",
    "test_dataset = pd.read_pickle('numpy_test_data.pkl')\n",
    "label_mapping = pd.read_pickle('label_mapping.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the structure of the datasets\n",
    "print(\"Train Dataset Type:\", type(train_dataset))\n",
    "print(\"Train Dataset Sample:\", train_dataset[:2])  # Print first 2 items for inspection\n",
    "\n",
    "print(\"Validation Dataset Type:\", type(val_dataset))\n",
    "print(\"Validation Dataset Sample:\", val_dataset[:2])  # Print first 2 items for inspection\n",
    "\n",
    "print(\"Test Dataset Type:\", type(test_dataset))\n",
    "print(\"Test Dataset Sample:\", test_dataset[:2])  # Print first 2 items for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datasets to TensorDatasets\n",
    "train_tensors = convert_to_tensors(train_dataset[0], train_dataset[1])\n",
    "val_tensors = convert_to_tensors(val_dataset[0], val_dataset[1])\n",
    "test_tensors = convert_to_tensors(test_dataset[0], test_dataset[1])\n",
    "\n",
    "# Save the converted datasets to new pickle files\n",
    "#save_dataset_to_pickle(train_tensors, 'train_data_augmented_3_tensors.pkl')\n",
    "save_dataset_to_pickle(train_tensors, 'train_data_3_tensors.pkl')\n",
    "save_dataset_to_pickle(val_tensors, 'val_data_3_tensors.pkl')\n",
    "save_dataset_to_pickle(test_tensors, 'test_data_3_tensors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets for our models\n",
    "#train_tensors = pd.read_pickle('train_data_augmented_3_tensors.pkl')\n",
    "train_tensors = pd.read_pickle('train_data_3_tensors.pkl')\n",
    "val_tensors = pd.read_pickle('val_data_3_tensors.pkl')\n",
    "test_tensors = pd.read_pickle('test_data_3_tensors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for each set\n",
    "train_loader = DataLoader(train_tensors, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_tensors, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_tensors, batch_size=32, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
